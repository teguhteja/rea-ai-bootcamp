   Communicating with Embedded Data in Documents â€“ Mastering AI Bootcamp 

[Mastering AI Bootcamp](../index.html)

Communicating with Embedded Data in Documents
=============================================

*   Toolkit
    
    *   Python
        
        *   Jupyter Notebook
            
            *   [Jupyter Notebooks](../01_toolkits/00_python/00_jupyter-notebooks/00_installation-and-setup.html)
                
            *   [Notebook cells](../01_toolkits/00_python/00_jupyter-notebooks/01_notebook-cells.html)
                
            *   [Markdown and Formatting](../01_toolkits/00_python/00_jupyter-notebooks/02_markdown-and-formatting.html)
                
            *   [Kernel Management](../01_toolkits/00_python/00_jupyter-notebooks/03_kernel-management.html)
                
            *   [Magic Commands](../01_toolkits/00_python/00_jupyter-notebooks/04_magic-commands.html)
                
            *   [JupyterLab](../01_toolkits/00_python/00_jupyter-notebooks/05_jupyterlab.html)
                
        *   [Python Basics](../01_toolkits/00_python/01_python-basics.html)
            
        *   [Control Structures](../01_toolkits/00_python/02_control-structures.html)
            
        *   [Function](../01_toolkits/00_python/03_function.html)
            
        *   [Data Structures](../01_toolkits/00_python/04_data-structures.html)
            
        *   [Modules and Packages](../01_toolkits/00_python/05_modules-and-packages.html)
            
        *   [Working with Files](../01_toolkits/00_python/06_working-with-files.html)
            
        *   [Virtual Environments](../01_toolkits/00_python/07_virtual-environments.html)
            
        *   OOP
            
            *   [Object oriented programming: Fitting functionality into single objects](../01_toolkits/00_python/08_oop/00_oop.html)
                
            *   [Inheritance](../01_toolkits/00_python/08_oop/01_oop_inheritance.html)
                
    *   Version Control
        
        *   [Introduction to Version Control](../01_toolkits/01_version-control/00_introduction-to-version-control.html)
            
        *   [Git Introduction](../01_toolkits/01_version-control/01_introduction-git.html)
            
        *   Git Command
            
            *   [`Init`](../01_toolkits/01_version-control/02_git-command-local/00_init.html)
                
            *   [Snapshotting](../01_toolkits/01_version-control/02_git-command-local/01_snapshotting.html)
                
            *   [`git remote add`](../01_toolkits/01_version-control/02_git-command-local/02_git-remote.html)
                
            *   [Basic branch and merge](../01_toolkits/01_version-control/02_git-command-local/03_basic-branch-and-merge.html)
                
            *   [`.gitignore`](../01_toolkits/01_version-control/02_git-command-local/04_gitignore.html)
                
        *   [Github](../01_toolkits/01_version-control/03_github.html)
            
    *   Fundamental of Statistics
        
        *   [Descriptive Statistics](../01_toolkits/02_foundational_statistics/00_descriptive_statistics.html)
            
        *   [Fundamentals of Probability](../01_toolkits/02_foundational_statistics/01_fundamentals_of_probability.html)
            
        *   [Data Analysis and Interpretation](../01_toolkits/02_foundational_statistics/02_data_analysis_and_interpretation.html)
            
        *   [Distributions in Statistics](../01_toolkits/02_foundational_statistics/03_distributions_statistics.html)
            
        *   [Bayesian Theory](../01_toolkits/02_foundational_statistics/04_bayesian_theory.html)
            
    *   [Pandas](../01_toolkits/03_pandas/00_pandas.html)
        
    *   [Visualization](../01_toolkits/04_visualization/00_visualization.html)
        
*   * * *
    
*   Machine Learning Fundamental
    
    *   [What is Machine Learning](../02_machine-learning-fundamental/00_what-is-machine-learning.html)
        
    *   [Introduction to Machine Learning](../02_machine-learning-fundamental/01_machine-learning-fundamental.html)
        
    *   [Linear Regression](../02_machine-learning-fundamental/02_linear-equation.html)
        
    *   [Supervised Learning](../02_machine-learning-fundamental/03_supervised-learning.html)
        
    *   [Scalar](../02_machine-learning-fundamental/04_matrix-and-vector.html)
        
    *   [Visualizing linear algebra as vector spaces](../02_machine-learning-fundamental/05_linear-algebra.html)
        
    *   [k-Nearest Neighbors (kNN)](../02_machine-learning-fundamental/06_knn.html)
        
    *   [Classification](../02_machine-learning-fundamental/07_classification.html)
        
    *   [Decision Tree](../02_machine-learning-fundamental/08_decision-tree.html)
        
    *   [Support Vector Machines](../02_machine-learning-fundamental/09_svm.html)
        
    *   [Direction of a vector](../02_machine-learning-fundamental/10_supplemental_svm.html)
        
    *   [Unsupervised Learning](../02_machine-learning-fundamental/11_unsupervised-learning.html)
        
    *   [Anomaly Detection](../02_machine-learning-fundamental/12_anomaly-detection.html)
        
    *   [Principal Component Analysis](../02_machine-learning-fundamental/13_pca.html)
        
    *   [Covariance formula and variance](../02_machine-learning-fundamental/14_supplemental-pca.html)
        
*   * * *
    
*   Deep Learning
    
    *   [Deep Learning](../03_deep-learning/00_deep-learning.html)
        
    *   [Deep Learning Model](../03_deep-learning/01_deep-learning-model.html)
        
    *   [Calculus](../03_deep-learning/02_calculus-for-deep-learning.html)
        
    *   [Gradient Descend and Backpropagation](../03_deep-learning/03_gradient-descent-and-backpropagation.html)
        
    *   [Pytorch Basic](../03_deep-learning/04_pytorch-basic.html)
        
    *   [Gradient Descent with PyTorch](../03_deep-learning/05_pytorch-gradient-descent.html)
        
    *   [Pytorch Dimension Modification](../03_deep-learning/06_pytorch-dimension.html)
        
    *   [Pytorch Application](../03_deep-learning/07_pytorch-application.html)
        
    *   [Pytorch MNIST](../03_deep-learning/08_pytorch-mnist.html)
        
*   * * *
    
*   Model Usage
    
    *   Introduction
        
        *   [Hugging Face](../04_model-usage/00-introduction/00_transformers_hugging_face.html)
            
    *   Pipeline
        
        *   [Pipelines](../04_model-usage/01-pipeline/00_pipeline.html)
            
        *   [Choosing the Right Processing Unit for Machine Learning: CPU, GPU, or TPU?](../04_model-usage/01-pipeline/01_cpu-gpu-tpu.html)
            
    *   Model Hub
        
        *   [Model Hub ðŸ—ƒï¸](../04_model-usage/02-model-hub/00_models.html)
            
    *   Transfer Learning
        
        *   [Transfer Learning](../04_model-usage/03-transfer-learning/00_transfer_learning.html)
            
        *   [Model Deployment](../04_model-usage/03-transfer-learning/01_model_deployment.html)
            
    *   Gradio
        
        *   [Gradio](../04_model-usage/04-gradio/00_gradio.html)
            
*   * * *
    
*   Database
    
    *   SQL
        
        *   [SQL Fundamentals with Python - Database](../05_database/00_sql/00_sql-database.html)
            
        *   [SQL Fundamentals with Python - Tables](../05_database/00_sql/01_sql-table.html)
            
        *   [SQL Fundamentals with Python - Joins](../05_database/00_sql/02_sql-joins.html)
            
    *   Elasticsearch
        
        *   [Introduction to Elasticsearch](../05_database/01_elasticsearch/00_introduction.html)
            
        *   [Installation and Configuration](../05_database/01_elasticsearch/01_installation-and-configuration.html)
            
        *   [Data Modeling](../05_database/01_elasticsearch/02_data-modeling.html)
            
        *   [Elasticsearch In Practice](../05_database/01_elasticsearch/03_elasticsearch-in-practice.html)
            
        *   [Query](../05_database/01_elasticsearch/04_query.html)
            
        *   [Snapshot](../05_database/01_elasticsearch/05_snapshot.html)
            
*   * * *
    
*   Computer Vision
    
    *   CNN
        
        *   [Computer Vision](../06_computer-vision/00_cnn/00_cnn-intro.html)
            
        *   [Hello World in Image Classification](../06_computer-vision/00_cnn/01_nn-vs-cnn.html)
            
        *   [CIFAR10 comparison for regular Neural Network vs CNN](../06_computer-vision/00_cnn/02_nn-vs-cnn-cifar10.html)
            
        *   [Convolution Layer](../06_computer-vision/00_cnn/03_convolution-layer.html)
            
        *   [POOLING LAYER](../06_computer-vision/00_cnn/04_pooling-layer.html)
            
        *   [Fully Connected Layer](../06_computer-vision/00_cnn/05_fully-connected-layer.html)
            
        *   [Training](../06_computer-vision/00_cnn/06_training.html)
            
        *   [Pretrained CNN Model](../06_computer-vision/00_cnn/07_pretrained-model.html)
            
        *   [Applied CNN: Object Detection and YOLO in Action](../06_computer-vision/00_cnn/08_object-detection.html)
            
    *   Stable Diffusion
        
        *   Introduction
            
            *   [Intro to Stable Diffusion](../06_computer-vision/01_stable-diffusion/00_intro/intro.html)
                
        *   Basic
            
            *   [Stable Diffusion - Basic](../06_computer-vision/01_stable-diffusion/01_basic/Stable_Diffusion_Basic.html)
                
        *   Fine Tuning
            
            *   [Stable Difussion Fine-tuning with Dreambooth](../06_computer-vision/01_stable-diffusion/02_fine_tuning/Stable_Diffusion_Fine_tuning.html)
                
        *   ControlNet
            
            *   [ControlNet with Stable Diffusion](../06_computer-vision/01_stable-diffusion/03_controlnet/Stable_Diffusion_ControlNet.html)
                
*   * * *
    
*   NLP
    
    *   [Intuition](../07_nlp/00_intuition.html)
        
    *   [Preprocessing](../07_nlp/01_preprocess.html)
        
    *   [Feature extraction](../07_nlp/02_feature_extraction.html)
        
    *   [Second architecture: Using Word Embedding for sentiment classification](../07_nlp/03_word_embedding_intuition.html)
        
    *   [ASCII](../07_nlp/04_word_embedding.html)
        
    *   [Generate Word Embedding With Word2Vec](../07_nlp/05_word2vec.html)
        
    *   [RNN](../07_nlp/06_RNN.html)
        
    *   [Seq2Seq With RNN](../07_nlp/07_Seq2Seq_with_RNN.html)
        
    *   [Problem With RNN](../07_nlp/08_attention.html)
        
    *   [Understanding Different Transformer Architectures](../07_nlp/09_understanding_different_architectures.html)
        
*   * * *
    
*   Langchain
    
    *   Prompt Engineering
        
        *   [NovelAI](../08_langchain/00_prompt-engineering/00_NovelAI.html)
            
        *   [Intro to Prompt in Generative AI](../08_langchain/00_prompt-engineering/01_intro-to-prompt-engineering.html)
            
    *   [API with FastAPI](../08_langchain/01_fast_api.html)
        
    *   [LangChain: A Python Library for Building NLP Applications](../08_langchain/02_intro_to_langchain.html)
        
    *   [Basic Usage LangChain](../08_langchain/03-basic_langchain.html)
        
    *   Chain
        
        *   [Chain](../08_langchain/04_chain/00_chain.html)
            
        *   [Chain Exercise](../08_langchain/04_chain/01_chain_exercise.html)
            
        *   [Chain Exercise](../08_langchain/04_chain/02_chain_exercise_answer.html)
            
    *   [Agent](../08_langchain/05_agent.html)
        
    *   [Memory and LangChain](../08_langchain/06_memory.html)
        
    *   [Memory Exercise Answer Key](../08_langchain/06-memory-exercise-answer-key.html)
        
    *   [Communicating with Embedded Data in Documents](../08_langchain/07.qna-with-data-in-the-document.html)
        
*   * * *
    
*   Machine Learning Operations
    
    *   Docker
        
        *   [Introduction to Docker](../09_mlops/00_docker/00_intro_setup_docker.html)
            
        *   [Building Docker Images for Python Apps](../09_mlops/00_docker/01_build_docker_images.html)
            
        *   [Deploying Python Apps with Docker Compose](../09_mlops/00_docker/02_deploy_docker_images.html)
            
    *   Wan DB
        
        *   [Introduction to WanDB](../09_mlops/01_wandb/00_wandb_intro_setup.html)
            
        *   [Dashboards in WanDB](../09_mlops/01_wandb/01_wandb_dashboard.html)
            
        *   [Cnn and Wandb Tracking](../09_mlops/01_wandb/cnn_and_wandb_tracking.html)
            
        *   [Fine-tuning a model on a text classification task](../09_mlops/01_wandb/Text_Classification_on_GLUE.html)
            

On this page
------------

*   [Illustration of the problem](#illustration-of-the-problem)
*   [Concept Communicating with Embedded Data in Documents in LangChain](#concept-communicating-with-embedded-data-in-documents-in-langchain)
    *   [Load The Document](#load-the-document)
    *   [Store Document to Memory](#store-document-to-memory)
    *   [Querying Data](#querying-data)

Communicating with Embedded Data in Documents
=============================================

Illustration of the problem
---------------------------

* * *

A company named **Tech Solutions** has a large database of technical documents related to their products.

These documents contain information about product specifications, troubleshooting guides, and user manuals.

The company wants to provide better customer support by allowing users to ask questions about their products and get instant answers.

**Could they achieve their goal?**

The answer is yes, and they did it by using AI chatbot capable of comprehending and retrieving information from these documents.

So, the aim is to enable conversations like the following:

> **User:** Hi, Iâ€™m having trouble setting up my new Tech Solutions router. Can you help?
> 
> **AI Chatbot:** Of course, Iâ€™m here to help. Could you please tell me the model of your router?
> 
> **User:** Itâ€™s the Tech Solutions Router Model X100.
> 
> **AI Chatbot:** Thank you for the information. Let me fetch the setup guide for you.
> 
> > **_The AI chatbot scans the database of documents, finds the setup guide for the Tech Solutions Router Model X100, and extracts the relevant information._**
> 
> **AI Chatbot:**
> 
> Here are the basic steps to set up your Tech Solutions Router Model X100:
> 
> 1.  Connect the router to your modem using the provided Ethernet cable.
> 2.  Plug the router into a power source and turn it on.
> 3.  Connect your device to the routerâ€™s network. The default network name and password are on the bottom of the router.
> 4.  Open a web browser and type in the routerâ€™s IP address (found on the bottom of the router) to access the setup page.
> 5.  Follow the on-screen instructions to complete the setup.
> 
> Please let me know if you need help with any of these steps.

This scenario illustrates how an AI chatbot can engage with data within a document to offer real-time assistance to users. The AI chatbot leverages natural language processing to comprehend user queries, and machine learning algorithms to locate and extract pertinent information from the documents.

Now, let us try to create this using LangChain.

Concept Communicating with Embedded Data in Documents in LangChain
------------------------------------------------------------------

LangChain provides a powerful way to interact with your data by enabling a large language model (LLM) to answer questions based on the content of your documents.

Hereâ€™s a overview of the process:

1.  Load The Document
2.  Store Document to Memory
3.  Querying Data

* * *

### Load The Document

The first step is to load your document into LangChain. This can be done using LangChainâ€™s document loaders, which can handle data from a variety of sources. The document could be a text file, a CSV file, a webpage, or any other type of document that contains the data you want the LLM to interact with.

For example we will load a text file containing the text of the book `Alice in Wonderland` by Lewis Carroll. The text file is located in the `data` directory of the LangChain repository.

https://gist.githubusercontent.com/phillipj/4944029/raw/75ba2243dd5ec2875f629bf5d79f6c1e4b5a8b46/alice\_in\_wonderland.txt

    from langchain.document_loaders import TextLoader
    
    loader = TextLoader("./documents/alice_in_wonderland.txt")
    pages = loader.load()

Each page is a `Document`.

A `Document` contains text (`page_content`) and `metadata`.

    len(pages)
    
    page = pages[0]

    print(page.page_content[200:500])
    page.metadata

#### **Document Splitting**

Document splitting is a crucial step in the process of preparing data for AI models.

It involves breaking down large documents into smaller, manageable chunks.

This process may seem straightforward, but itâ€™s filled with subtleties that can significantly impact the performance of AI models down the line.

##### **Why is Document Splitting Important?**

Consider a document containing information about the specifications of a Toyota Camry. If we split the document incorrectly, we might end up with one chunk containing half a sentence about the carâ€™s specifications and another chunk containing the rest.

This split could prevent an AI model from correctly answering a question about the carâ€™s specifications because the relevant information is spread across two chunks.

To avoid such issues, we need to split documents in a way that keeps semantically relevant information together. This process involves defining a chunk size and a chunk overlap.

##### **Chunk Size and Chunk Overlap**

The chunk size refers to the size of each chunk, which can be measured in various ways, such as the number of characters or tokens.

The chunk overlap is a small overlap between two chunks, like a sliding window, which ensures some consistency and continuity between chunks.

###### Example chunking

Consider we have a sentence:

`Artificial intelligence is a branch of computer science that aims to create intelligent machines that work and react like humans.`

If we decide to chunk this sentence into chunks of 10 words each, but without any overlap, we would end up with the following chunks:

Chunk 1: `Artificial intelligence is a branch of computer science that aims to create` Chunk 2: `intelligent machines that work and react like humans.`

The first chunk contains the first 10 words of the sentence, and the second chunk contains the remaining words. This split is not ideal because it will prevent an AI model from understanding the sentenceâ€™s meaning.

Now, letâ€™s try to split the sentence into chunks of 10 words each, but with an overlap of 3 words. This time, we would end up with the following chunks:

Chunk 1: `Artificial intelligence is a branch of computer science that aims to create` Chunk 2: `that aims to create intelligent machines that work and react like humans.`

Here, `that aims to create` is the overlap between the two chunks. This overlap can help in maintaining the context when these chunks are processed independently.

##### **Text Splitters**

Text splitters in Lang Chain split documents into chunks based on the defined chunk size and overlap.

They can vary in how they split the chunks and measure the length of the chunks.

Some splitters even use smaller models to determine the end of a sentence and use that as a splitting point.

    from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter

    r_splitter = RecursiveCharacterTextSplitter(
        chunk_size=4,
        chunk_overlap=2
    )

    text1 = 'abcdefghijklmnopqrstuvwxyz'
    r_splitter.split_text(text1)

    text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'
    r_splitter.split_text(text2)

    text3 = "a b c d e f g h i j k l m n o p q r s t u v w x y z"
    r_splitter.split_text(text3)

    c_splitter = CharacterTextSplitter(
        separator = ' ',
        chunk_size=10,
        chunk_overlap=2
    )

    c_splitter.split_text("hello world \n I am a text splitter \n please split me \n thank you")

##### **Metadata and Document Type**

Maintaining metadata across all chunks and adding new pieces of metadata when relevant is another crucial aspect of document splitting. The type of document weâ€™re working with can also influence how we split it. For instance, code documents might require different splitting strategies compared to text documents.

##### **Split The Document**

We will take the document above and split it into chunks.

We can use the recursive character text splitter and the character text splitter, two common types of text splitters in Lang Chain.

We can experiment with different chunk sizes and overlaps to see how they affect the splitting.

After splitting, we can compare the length of the original document with the lengths of the chunks to see how many chunks weâ€™ve created. We can also check the metadata of the chunks to ensure it matches the metadata of the original document.

    from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter

    chunk_size =10
    chunk_overlap = 2
    
    r_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap
    )

    textSplit = r_splitter.split_text(page.page_content)
    
    print(textSplit)

    c_splitter = CharacterTextSplitter(
        separator = '\n',
        chunk_size=100,
        chunk_overlap=10
    )

    charSplit = c_splitter.split_text(page.page_content)
    
    print(charSplit)

### Store Document to Memory

Storing and searching over unstructured data often involves embedding the data and storing the resulting embedding vectors. At the time of a query, the unstructured query is embedded and the embedding vectors that are â€˜most similarâ€™ to the embedded query are retrieved. This process is managed by a vector store.

A vector store is responsible for storing embedded data and performing vector search. It stores vector representations, or embeddings, of the data. These embeddings encapsulate the semantic meaning of the text, enabling the Language Learning Model (LLM) to comprehend and interact with the content of the document.

#### **Why is Vector Search Important?**

Vector search is a crucial component of many AI applications. It enables the AI model to retrieve relevant information from a large corpus of documents.

//<!\[CDATA\[ window.\_\_mirage2 = {petok:"jgm3M6Tijz9n9uoHvxu8DiorQmDhWwo5QMAbRdxepIg-1800-0.0.1.1"}; //\]\]> 

![](https://python.langchain.com/assets/images/vector_stores-9dc1ecb68c4cb446df110764c9cc07e0.jpg)

Vector Search

For example, a chatbot can use vector search to retrieve information from a database of documents and answer user queries.

#### **Vector Store in LangChain**

LangChain provides a robust and flexible platform that supports a multitude of integration methods with Vector Stores. This versatility allows users to choose the most suitable vector store for their specific needs. In this particular instance, we will delve into the process of integrating with FAISS, a library developed by Facebook AI that is renowned for efficient similarity search and clustering of dense vectors.

FAISS is particularly beneficial for users who need to manage large databases and perform quick nearest-neighbor searches on high dimensional vectors. Itâ€™s a powerful tool that can significantly enhance the efficiency of handling unstructured data.

For those interested in exploring other options, LangChain supports a wide range of Vector Stores. A comprehensive list of these supported Vector Stores can be found at the following link: [LangChain Vector Stores](https://python.langchain.com/docs/integrations/vectorstores/).

    import os
    import openai
    import sys
    sys.path.append('../..')
    
    from dotenv import load_dotenv, find_dotenv
    _ = load_dotenv(find_dotenv()) # read local .env file
    
    openai.api_key  = os.environ['OPENAI_API_KEY']

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size = 100,
        chunk_overlap = 25
    )

    splits = text_splitter.split_text(page.page_content)

    len(splits)

    from langchain.embeddings.openai import OpenAIEmbeddings
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain.vectorstores import FAISS

    from langchain.document_loaders import TextLoader
    
    loader = TextLoader("./documents/alice_in_wonderland.txt")
    documents = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
    docs = text_splitter.split_documents(documents)
    
    embeddings = OpenAIEmbeddings()

    db = FAISS.from_documents(docs, embeddings)

### Querying Data

With the document stored in memory, you can now query the data. This involves creating a query and passing it to the vector store. The vector store will return the most relevant documents based on the query. These documents can then be passed to the LLM to generate a response.

In this way, LangChain allows you to chat with your data, enabling the LLM to answer questions based on the content of your documents. This can be particularly useful when dealing with large amounts of data or proprietary documents that the LLM was not originally trained on.

The First step is to imports the `RetrievalQA` module from the `langchain.chains` package.

`RetrievalQA` stands for Retrieval Question Answering. Itâ€™s a type of model that retrieves answers to questions based on a given context.

In the context of LangChain, this module is used to retrieve the most relevant information from the stored data based on the userâ€™s query.

And then imports the `ChatOpenAI` module from the `langchain.chat_models` package.

    from langchain.chains import RetrievalQA
    from langchain.chat_models import ChatOpenAI

After that, we setup the language model and retrival class.

    OpenAIModel = "gpt-4"
    llm = ChatOpenAI(model=OpenAIModel, temperature=0.1)
    
    qa = RetrievalQA.from_chain_type(llm=llm, retriever=db.as_retriever())

After creating the retrieval class, we can pass the query to the `get_answers` method of the retrieval class. Thi method will return the most relevant answers to the query based on the stored data in the vector store.

    query = "please mention all of the characters?"
    
    qa.run(query)

    query = "who is the main character?"
    
    qa.run(query)

    query = "please create synopsis from the story?"
    
    qa.run(query)

    query = "what is the ending of the story?"
    
    qa.run(query)

If the query is not relevant to the stored data, the method will return answers like `I don't know` or `I don't understand`.

    query = "who is president of indonesia?"
    
    qa.run(query)

Back to top


Â© Ruangguru Engineering 2024. All rights reserved