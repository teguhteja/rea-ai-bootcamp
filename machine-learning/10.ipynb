{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[ 0.99986773 -0.66640213]]\n",
      "Bias: [-0.6665344]\n",
      "Support Vectors:\n",
      " [[-2.  -2.5]\n",
      " [ 1.   2. ]\n",
      " [ 1.  -1. ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "X = np.array([[3, 0.5], [5, -1], [1, -1], [6, 2], [4, 2], [-2, -2.5], [-2, 3], [-5, 1], [-3, -2], [-4, 2], [1, 2]])\n",
    "y = np.array([1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1])  # Blue points (class 1), Red points (class 0) as -1\n",
    "\n",
    "# Create an SVM classifier with a hard margin (What is hard margin?, what is C parameter? We'll learn about it later)\n",
    "clf = svm.SVC(kernel='linear', C=1e5)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# You can now use the trained classifier to make predictions on new data\n",
    "# Get the coefficients (weights) of the hyperplane\n",
    "coefficients = clf.coef_\n",
    "print(\"Weights:\", coefficients)\n",
    "\n",
    "# Get the bias (intercept) of the hyperplane\n",
    "intercept_ = clf.intercept_\n",
    "print(\"Bias:\", intercept_)\n",
    "\n",
    "# Get the Support Vectors\n",
    "support_vectors = clf.support_vectors_\n",
    "print(\"Support Vectors:\\n\", support_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba2d269e7eb482c80bc4f63b2c50b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='x1', max=10.0, min=-10.0), FloatSlider(value=0.0, deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.interactive_classification(x1=(-10.0, 10.0), x2=(-10.0, 10.0))>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "def classify_point(x):\n",
    "    \"\"\"\n",
    "    Classify a point as 'Blue' or 'Red' using the hyperplane from the SVM.\n",
    "    \n",
    "    Args:\n",
    "    x (array-like): The coordinates of the point as a tuple or list.\n",
    "\n",
    "    Returns:\n",
    "    str: 'Blue' if the point is above the hyperplane, 'Red' otherwise.\n",
    "    \"\"\"\n",
    "    w = np.array([coefficients[0][0], coefficients[0][1]])  # Coefficients of the hyperplane\n",
    "    b = intercept_[0]  # Intercept of the hyperplane\n",
    "    \n",
    "    # Hyperplane equation using dot product: np.dot(w, x) + b\n",
    "    result = np.dot(w, x) + b\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Function to plot the point and the hyperplane\n",
    "def plot_point(x1, x2):\n",
    "    point = np.array([x1, x2])\n",
    "    result = classify_point(point)\n",
    "    classification = 'Blue' if result >= 0 else 'Red'\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.axhline(0, color='grey', lw=1)\n",
    "    plt.axvline(0, color='grey', lw=1)\n",
    "\n",
    "    # Plotting the hyperplane\n",
    "    x_vals = np.linspace(-10, 10, 100)\n",
    "    y_vals = (-(coefficients[0][0] * x_vals) - intercept_[0]) / coefficients[0][1]\n",
    "    plt.plot(x_vals, y_vals, 'green', label='Hyperplane')\n",
    "\n",
    "    #Plotting the line that goes through the support vector with class 1\n",
    "    y_vals_1 = (1-(coefficients[0][0] * x_vals) - intercept_[0]) / coefficients[0][1]\n",
    "    plt.plot(x_vals, y_vals_1, 'purple', label='Line that goes through support vector with class 1', linestyle='--')\n",
    "    \n",
    "    #Plotting the line that goes through the support vector with class -1\n",
    "    y_vals_2 = (-1-(coefficients[0][0] * x_vals) - intercept_[0]) / coefficients[0][1]\n",
    "    plt.plot(x_vals, y_vals_2, 'purple', label='Line that goes through support vector with class -1', linestyle='--')\n",
    "\n",
    "    # Plotting the point\n",
    "    plt.scatter(x1, x2, color=classification.lower(), label=f'Point ({x1}, {x2})')\n",
    "    plt.xlim(-10, 10)\n",
    "    plt.ylim(-10, 10)\n",
    "    plt.xlabel('$x_1$')\n",
    "    plt.ylabel('$x_2$')\n",
    "    plt.title('Point Classification with Hyperplane')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return classification, result\n",
    "\n",
    "# Interactive function\n",
    "def interactive_classification(x1=(-10.0, 10.0), x2=(-10.0, 10.0)):\n",
    "    classification, result = plot_point(x1, x2)\n",
    "    print(f\"The point ({x1}, {x2}) is classified as '{classification}' with result {result:.4f}.\")\n",
    "\n",
    "interact(interactive_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[ 0.46068003 -0.25749064]]\n",
      "Bias: [0.32359972]\n",
      "Support Vectors:\n",
      " [[-4.75 -3.36]\n",
      " [-1.89  1.76]\n",
      " [ 1.3  -0.3 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "X = np.array([\n",
    "    [3.00, 1.00], [3.07, 1.18], [1.48, -2.39], [6.77, -2.18], [5.83, -0.21], [3.67, -3.26], \n",
    "    [3.58, 3.02], [-0.09, -3.42], [1.45, -1.58], [2.79, 1.18], [6.10, -1.52], [6.46, -0.11], \n",
    "    [6.70, -2.54], [1.30, -0.30], [1.75, -3.09], [2.80, 0.97], [3.28, 2.76], [0.59, -1.67], \n",
    "    [6.20, -1.50], [6.52, 0.18], [3.28, 2.76], [0.59, -1.67], [6.20, -1.50], [6.52, 0.18], \n",
    "    [4.06, 0.75], [5.10, -0.73], [4.89, -0.03], [6.31, 0.89], [5.54, 0.30], [4.66, 1.55], \n",
    "    [5.48, -2.17], [4.27, -1.70], [5.65, -1.32], [4.84, -2.93], [5.38, 0.58], [5.00, 1.34], \n",
    "    [4.71, 0.84], [5.96, -0.79], [4.54, 0.30], [5.73, -0.61], [-2.00, 3.00], [-5.80, 3.44], \n",
    "    [-3.69, 3.85], [-1.63, 3.56], [-4.67, -0.32], [-4.58, 1.83], [-3.81, 3.38], [-2.90, 0.41], \n",
    "    [-4.69, -2.15], [-4.75, -3.36], [-2.40, 1.72], [-1.91, 2.53], [-5.73, 1.52], [-5.70, -0.21], \n",
    "    [-5.87, -2.00], [-1.35, 2.96], [-4.71, -2.75], [-6.62, 0.79], [-5.32, 1.10], [-1.89, 1.76]\n",
    "])\n",
    "\n",
    "\n",
    "y = np.array([\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "])\n",
    "\n",
    "\n",
    "# Create an SVM classifier with a hard margin (What is hard margin?, what is C parameter? We'll learn about it later)\n",
    "clf = svm.SVC(kernel='linear', C=1e5)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# You can now use the trained classifier to make predictions on new data\n",
    "# Get the coefficients (weights) of the hyperplane\n",
    "coefficients = clf.coef_\n",
    "print(\"Weights:\", coefficients)\n",
    "\n",
    "# Get the bias (intercept) of the hyperplane\n",
    "intercept_ = clf.intercept_\n",
    "print(\"Bias:\", intercept_)\n",
    "\n",
    "# Get the Support Vectors\n",
    "support_vectors = clf.support_vectors_\n",
    "print(\"Support Vectors:\\n\", support_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[ 1.50867809 -0.78160554]]\n",
      "Bias: [-1.19552197]\n",
      "Support Vectors:\n",
      " [[ 0.   -0.25]\n",
      " [ 1.3  -0.3 ]\n",
      " [ 0.59 -1.67]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "X = np.array([\n",
    "    [3.00, 1.00], [3.07, 1.18], [1.48, -2.39], [6.77, -2.18], [5.83, -0.21], [3.67, -3.26], \n",
    "    [3.58, 3.02], [-0.09, -3.42], [1.45, -1.58], [2.79, 1.18], [6.10, -1.52], [6.46, -0.11], \n",
    "    [6.70, -2.54], [1.30, -0.30], [1.75, -3.09], [2.80, 0.97], [3.28, 2.76], [0.59, -1.67], \n",
    "    [6.20, -1.50], [6.52, 0.18], [3.28, 2.76], [0.59, -1.67], [6.20, -1.50], [6.52, 0.18], \n",
    "    [4.06, 0.75], [5.10, -0.73], [4.89, -0.03], [6.31, 0.89], [5.54, 0.30], [4.66, 1.55], \n",
    "    [5.48, -2.17], [4.27, -1.70], [5.65, -1.32], [4.84, -2.93], [5.38, 0.58], [5.00, 1.34], \n",
    "    [4.71, 0.84], [5.96, -0.79], [4.54, 0.30], [5.73, -0.61], [-2.00, 3.00], [-5.80, 3.44], \n",
    "    [-3.69, 3.85], [-1.63, 3.56], [-4.67, -0.32], [-4.58, 1.83], [-3.81, 3.38], [-2.90, 0.41], \n",
    "    [-4.69, -2.15], [-4.75, -3.36], [-2.40, 1.72], [-1.91, 2.53], [-5.73, 1.52], [-5.70, -0.21], \n",
    "    [-5.87, -2.00], [-1.35, 2.96], [-4.71, -2.75], [-6.62, 0.79], [-5.32, 1.10], [-1.89, 1.76],\n",
    "    [0, -0.25]\n",
    "])\n",
    "\n",
    "\n",
    "y = np.array([\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "    -1\n",
    "])\n",
    "\n",
    "\n",
    "# Create an SVM classifier with a hard margin (What is hard margin?, what is C parameter? We'll learn about it later)\n",
    "clf = svm.SVC(kernel='linear', C=1e5)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# You can now use the trained classifier to make predictions on new data\n",
    "# Get the coefficients (weights) of the hyperplane\n",
    "coefficients = clf.coef_\n",
    "print(\"Weights:\", coefficients)\n",
    "\n",
    "# Get the bias (intercept) of the hyperplane\n",
    "intercept_ = clf.intercept_\n",
    "print(\"Bias:\", intercept_)\n",
    "\n",
    "# Get the Support Vectors\n",
    "support_vectors = clf.support_vectors_\n",
    "print(\"Support Vectors:\\n\", support_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[ 1.37253163 -0.21883039]]\n",
      "Bias: [-0.39185024]\n",
      "Support Vectors:\n",
      " [[ 1.   -1.  ]\n",
      " [-0.09 -3.42]\n",
      " [ 1.3  -0.3 ]\n",
      " [ 1.75 -3.09]\n",
      " [ 0.59 -1.67]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "X = np.array([\n",
    "    [3.00, 1.00], [3.07, 1.18], [1.48, -2.39], [6.77, -2.18], [5.83, -0.21], [3.67, -3.26], \n",
    "    [3.58, 3.02], [-0.09, -3.42], [1.45, -1.58], [2.79, 1.18], [6.10, -1.52], [6.46, -0.11], \n",
    "    [6.70, -2.54], [1.30, -0.30], [1.75, -3.09], [2.80, 0.97], [3.28, 2.76], [0.59, -1.67], \n",
    "    [6.20, -1.50], [6.52, 0.18], [3.28, 2.76], [0.59, -1.67], [6.20, -1.50], [6.52, 0.18], \n",
    "    [4.06, 0.75], [5.10, -0.73], [4.89, -0.03], [6.31, 0.89], [5.54, 0.30], [4.66, 1.55], \n",
    "    [5.48, -2.17], [4.27, -1.70], [5.65, -1.32], [4.84, -2.93], [5.38, 0.58], [5.00, 1.34], \n",
    "    [4.71, 0.84], [5.96, -0.79], [4.54, 0.30], [5.73, -0.61], [-2.00, 3.00], [-5.80, 3.44], \n",
    "    [-3.69, 3.85], [-1.63, 3.56], [-4.67, -0.32], [-4.58, 1.83], [-3.81, 3.38], [-2.90, 0.41], \n",
    "    [-4.69, -2.15], [-4.75, -3.36], [-2.40, 1.72], [-1.91, 2.53], [-5.73, 1.52], [-5.70, -0.21], \n",
    "    [-5.87, -2.00], [-1.35, 2.96], [-4.71, -2.75], [-6.62, 0.79], [-5.32, 1.10], [-1.89, 1.76],\n",
    "    [1, -1]\n",
    "])\n",
    "\n",
    "\n",
    "y = np.array([\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    1,1, 1,1,1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "    -1,-1,-1,-1,-1,\n",
    "    -1\n",
    "])\n",
    "\n",
    "\n",
    "# Create an SVM classifier with a hard margin (What is hard margin?, what is C parameter? We'll learn about it later)\n",
    "clf = svm.SVC(kernel='linear', C=1e7)\n",
    "\n",
    "# Fit the classifier to the data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# You can now use the trained classifier to make predictions on new data\n",
    "# Get the coefficients (weights) of the hyperplane\n",
    "coefficients = clf.coef_\n",
    "print(\"Weights:\", coefficients)\n",
    "\n",
    "# Get the bias (intercept) of the hyperplane\n",
    "intercept_ = clf.intercept_\n",
    "print(\"Bias:\", intercept_)\n",
    "\n",
    "# Get the Support Vectors\n",
    "support_vectors = clf.support_vectors_\n",
    "print(\"Support Vectors:\\n\", support_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5191204"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([0.46068003, -0.25749064])\n",
    "x = np.array([-4, 0])\n",
    "b = 0.32359972\n",
    "\n",
    "1 - -1.0 * (w.dot(x) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47321089000000005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = np.array([0.46068003, -0.25749064])\n",
    "x = np.array([1, 1])\n",
    "b = 0.32359972\n",
    "\n",
    "1 - 1.0 * (w.dot(x) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
