   cnn\_and\_wandb\_tracking ‚Äì Mastering AI Bootcamp 

[Mastering AI Bootcamp](../../index.html)

*   Toolkit
    
    *   Python
        
        *   Jupyter Notebook
            
            *   [Jupyter Notebooks](../../01_toolkits/00_python/00_jupyter-notebooks/00_installation-and-setup.html)
                
            *   [Notebook cells](../../01_toolkits/00_python/00_jupyter-notebooks/01_notebook-cells.html)
                
            *   [Markdown and Formatting](../../01_toolkits/00_python/00_jupyter-notebooks/02_markdown-and-formatting.html)
                
            *   [Kernel Management](../../01_toolkits/00_python/00_jupyter-notebooks/03_kernel-management.html)
                
            *   [Magic Commands](../../01_toolkits/00_python/00_jupyter-notebooks/04_magic-commands.html)
                
            *   [JupyterLab](../../01_toolkits/00_python/00_jupyter-notebooks/05_jupyterlab.html)
                
        *   [Python Basics](../../01_toolkits/00_python/01_python-basics.html)
            
        *   [Control Structures](../../01_toolkits/00_python/02_control-structures.html)
            
        *   [Function](../../01_toolkits/00_python/03_function.html)
            
        *   [Data Structures](../../01_toolkits/00_python/04_data-structures.html)
            
        *   [Modules and Packages](../../01_toolkits/00_python/05_modules-and-packages.html)
            
        *   [Working with Files](../../01_toolkits/00_python/06_working-with-files.html)
            
        *   [Virtual Environments](../../01_toolkits/00_python/07_virtual-environments.html)
            
        *   OOP
            
            *   [Object oriented programming: Fitting functionality into single objects](../../01_toolkits/00_python/08_oop/00_oop.html)
                
            *   [Inheritance](../../01_toolkits/00_python/08_oop/01_oop_inheritance.html)
                
    *   Version Control
        
        *   [Introduction to Version Control](../../01_toolkits/01_version-control/00_introduction-to-version-control.html)
            
        *   [Git Introduction](../../01_toolkits/01_version-control/01_introduction-git.html)
            
        *   Git Command
            
            *   [`Init`](../../01_toolkits/01_version-control/02_git-command-local/00_init.html)
                
            *   [Snapshotting](../../01_toolkits/01_version-control/02_git-command-local/01_snapshotting.html)
                
            *   [`git remote add`](../../01_toolkits/01_version-control/02_git-command-local/02_git-remote.html)
                
            *   [Basic branch and merge](../../01_toolkits/01_version-control/02_git-command-local/03_basic-branch-and-merge.html)
                
            *   [`.gitignore`](../../01_toolkits/01_version-control/02_git-command-local/04_gitignore.html)
                
        *   [Github](../../01_toolkits/01_version-control/03_github.html)
            
    *   Fundamental of Statistics
        
        *   [Descriptive Statistics](../../01_toolkits/02_foundational_statistics/00_descriptive_statistics.html)
            
        *   [Fundamentals of Probability](../../01_toolkits/02_foundational_statistics/01_fundamentals_of_probability.html)
            
        *   [Data Analysis and Interpretation](../../01_toolkits/02_foundational_statistics/02_data_analysis_and_interpretation.html)
            
        *   [Distributions in Statistics](../../01_toolkits/02_foundational_statistics/03_distributions_statistics.html)
            
        *   [Bayesian Theory](../../01_toolkits/02_foundational_statistics/04_bayesian_theory.html)
            
    *   [Pandas](../../01_toolkits/03_pandas/00_pandas.html)
        
    *   [Visualization](../../01_toolkits/04_visualization/00_visualization.html)
        
*   * * *
    
*   Machine Learning Fundamental
    
    *   [What is Machine Learning](../../02_machine-learning-fundamental/00_what-is-machine-learning.html)
        
    *   [Introduction to Machine Learning](../../02_machine-learning-fundamental/01_machine-learning-fundamental.html)
        
    *   [Linear Regression](../../02_machine-learning-fundamental/02_linear-equation.html)
        
    *   [Supervised Learning](../../02_machine-learning-fundamental/03_supervised-learning.html)
        
    *   [Scalar](../../02_machine-learning-fundamental/04_matrix-and-vector.html)
        
    *   [Visualizing linear algebra as vector spaces](../../02_machine-learning-fundamental/05_linear-algebra.html)
        
    *   [k-Nearest Neighbors (kNN)](../../02_machine-learning-fundamental/06_knn.html)
        
    *   [Classification](../../02_machine-learning-fundamental/07_classification.html)
        
    *   [Decision Tree](../../02_machine-learning-fundamental/08_decision-tree.html)
        
    *   [Support Vector Machines](../../02_machine-learning-fundamental/09_svm.html)
        
    *   [Direction of a vector](../../02_machine-learning-fundamental/10_supplemental_svm.html)
        
    *   [Unsupervised Learning](../../02_machine-learning-fundamental/11_unsupervised-learning.html)
        
    *   [Anomaly Detection](../../02_machine-learning-fundamental/12_anomaly-detection.html)
        
    *   [Principal Component Analysis](../../02_machine-learning-fundamental/13_pca.html)
        
    *   [Covariance formula and variance](../../02_machine-learning-fundamental/14_supplemental-pca.html)
        
*   * * *
    
*   Deep Learning
    
    *   [Deep Learning](../../03_deep-learning/00_deep-learning.html)
        
    *   [Deep Learning Model](../../03_deep-learning/01_deep-learning-model.html)
        
    *   [Calculus](../../03_deep-learning/02_calculus-for-deep-learning.html)
        
    *   [Gradient Descend and Backpropagation](../../03_deep-learning/03_gradient-descent-and-backpropagation.html)
        
    *   [Pytorch Basic](../../03_deep-learning/04_pytorch-basic.html)
        
    *   [Gradient Descent with PyTorch](../../03_deep-learning/05_pytorch-gradient-descent.html)
        
    *   [Pytorch Dimension Modification](../../03_deep-learning/06_pytorch-dimension.html)
        
    *   [Pytorch Application](../../03_deep-learning/07_pytorch-application.html)
        
    *   [Pytorch MNIST](../../03_deep-learning/08_pytorch-mnist.html)
        
*   * * *
    
*   Model Usage
    
    *   Introduction
        
        *   [Hugging Face](../../04_model-usage/00-introduction/00_transformers_hugging_face.html)
            
    *   Pipeline
        
        *   [Pipelines](../../04_model-usage/01-pipeline/00_pipeline.html)
            
        *   [Choosing the Right Processing Unit for Machine Learning: CPU, GPU, or TPU?](../../04_model-usage/01-pipeline/01_cpu-gpu-tpu.html)
            
    *   Model Hub
        
        *   [Model Hub üóÉÔ∏è](../../04_model-usage/02-model-hub/00_models.html)
            
    *   Transfer Learning
        
        *   [Transfer Learning](../../04_model-usage/03-transfer-learning/00_transfer_learning.html)
            
        *   [Model Deployment](../../04_model-usage/03-transfer-learning/01_model_deployment.html)
            
    *   Gradio
        
        *   [Gradio](../../04_model-usage/04-gradio/00_gradio.html)
            
*   * * *
    
*   Database
    
    *   SQL
        
        *   [SQL Fundamentals with Python - Database](../../05_database/00_sql/00_sql-database.html)
            
        *   [SQL Fundamentals with Python - Tables](../../05_database/00_sql/01_sql-table.html)
            
        *   [SQL Fundamentals with Python - Joins](../../05_database/00_sql/02_sql-joins.html)
            
    *   Elasticsearch
        
        *   [Introduction to Elasticsearch](../../05_database/01_elasticsearch/00_introduction.html)
            
        *   [Installation and Configuration](../../05_database/01_elasticsearch/01_installation-and-configuration.html)
            
        *   [Data Modeling](../../05_database/01_elasticsearch/02_data-modeling.html)
            
        *   [Elasticsearch In Practice](../../05_database/01_elasticsearch/03_elasticsearch-in-practice.html)
            
        *   [Query](../../05_database/01_elasticsearch/04_query.html)
            
        *   [Snapshot](../../05_database/01_elasticsearch/05_snapshot.html)
            
*   * * *
    
*   Computer Vision
    
    *   CNN
        
        *   [Computer Vision](../../06_computer-vision/00_cnn/00_cnn-intro.html)
            
        *   [Hello World in Image Classification](../../06_computer-vision/00_cnn/01_nn-vs-cnn.html)
            
        *   [CIFAR10 comparison for regular Neural Network vs CNN](../../06_computer-vision/00_cnn/02_nn-vs-cnn-cifar10.html)
            
        *   [Convolution Layer](../../06_computer-vision/00_cnn/03_convolution-layer.html)
            
        *   [POOLING LAYER](../../06_computer-vision/00_cnn/04_pooling-layer.html)
            
        *   [Fully Connected Layer](../../06_computer-vision/00_cnn/05_fully-connected-layer.html)
            
        *   [Training](../../06_computer-vision/00_cnn/06_training.html)
            
        *   [Pretrained CNN Model](../../06_computer-vision/00_cnn/07_pretrained-model.html)
            
        *   [Applied CNN: Object Detection and YOLO in Action](../../06_computer-vision/00_cnn/08_object-detection.html)
            
    *   Stable Diffusion
        
        *   Introduction
            
            *   [Intro to Stable Diffusion](../../06_computer-vision/01_stable-diffusion/00_intro/intro.html)
                
        *   Basic
            
            *   [Stable Diffusion - Basic](../../06_computer-vision/01_stable-diffusion/01_basic/Stable_Diffusion_Basic.html)
                
        *   Fine Tuning
            
            *   [Stable Difussion Fine-tuning with Dreambooth](../../06_computer-vision/01_stable-diffusion/02_fine_tuning/Stable_Diffusion_Fine_tuning.html)
                
        *   ControlNet
            
            *   [ControlNet with Stable Diffusion](../../06_computer-vision/01_stable-diffusion/03_controlnet/Stable_Diffusion_ControlNet.html)
                
*   * * *
    
*   NLP
    
    *   [Intuition](../../07_nlp/00_intuition.html)
        
    *   [Preprocessing](../../07_nlp/01_preprocess.html)
        
    *   [Feature extraction](../../07_nlp/02_feature_extraction.html)
        
    *   [Second architecture: Using Word Embedding for sentiment classification](../../07_nlp/03_word_embedding_intuition.html)
        
    *   [ASCII](../../07_nlp/04_word_embedding.html)
        
    *   [Generate Word Embedding With Word2Vec](../../07_nlp/05_word2vec.html)
        
    *   [RNN](../../07_nlp/06_RNN.html)
        
    *   [Seq2Seq With RNN](../../07_nlp/07_Seq2Seq_with_RNN.html)
        
    *   [Problem With RNN](../../07_nlp/08_attention.html)
        
    *   [Understanding Different Transformer Architectures](../../07_nlp/09_understanding_different_architectures.html)
        
*   * * *
    
*   Langchain
    
    *   Prompt Engineering
        
        *   [NovelAI](../../08_langchain/00_prompt-engineering/00_NovelAI.html)
            
        *   [Intro to Prompt in Generative AI](../../08_langchain/00_prompt-engineering/01_intro-to-prompt-engineering.html)
            
    *   [API with FastAPI](../../08_langchain/01_fast_api.html)
        
    *   [LangChain: A Python Library for Building NLP Applications](../../08_langchain/02_intro_to_langchain.html)
        
    *   [Basic Usage LangChain](../../08_langchain/03-basic_langchain.html)
        
    *   Chain
        
        *   [Chain](../../08_langchain/04_chain/00_chain.html)
            
        *   [Chain Exercise](../../08_langchain/04_chain/01_chain_exercise.html)
            
        *   [Chain Exercise](../../08_langchain/04_chain/02_chain_exercise_answer.html)
            
    *   [Agent](../../08_langchain/05_agent.html)
        
    *   [Memory and LangChain](../../08_langchain/06_memory.html)
        
    *   [Memory Exercise Answer Key](../../08_langchain/06-memory-exercise-answer-key.html)
        
    *   [Communicating with Embedded Data in Documents](../../08_langchain/07.qna-with-data-in-the-document.html)
        
*   * * *
    
*   Machine Learning Operations
    
    *   Docker
        
        *   [Introduction to Docker](../../09_mlops/00_docker/00_intro_setup_docker.html)
            
        *   [Building Docker Images for Python Apps](../../09_mlops/00_docker/01_build_docker_images.html)
            
        *   [Deploying Python Apps with Docker Compose](../../09_mlops/00_docker/02_deploy_docker_images.html)
            
    *   Wan DB
        
        *   [Introduction to WanDB](../../09_mlops/01_wandb/00_wandb_intro_setup.html)
            
        *   [Dashboards in WanDB](../../09_mlops/01_wandb/01_wandb_dashboard.html)
            
        *   [Cnn and Wandb Tracking](../../09_mlops/01_wandb/cnn_and_wandb_tracking.html)
            
        *   [Fine-tuning a model on a text classification task](../../09_mlops/01_wandb/Text_Classification_on_GLUE.html)
            
```python
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torchvision
    from torchvision import transforms
    import wandb
    import random
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    
    # Define CNN architecture (example - customize as needed)
    class CNN(nn.Module):
        def __init__(self):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(3, 6, 5)  # Input channels, output channels, kernel size
            self.pool = nn.MaxPool2d(2, 2)  # Kernel size, stride (optional)
            self.conv2 = nn.Conv2d(6, 16, 5)
            self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Input features, output features
            self.fc2 = nn.Linear(120, 84)
            self.fc3 = nn.Linear(84, 10) # Output for 10 CIFAR-10 classes
    
        def forward(self, x):
            x = self.pool(F.relu(self.conv1(x)))
            x = self.pool(F.relu(self.conv2(x)))
            x = x.view(-1, 16 * 5 * 5)  # Flatten for fully-connected layers
            x = F.relu(self.fc1(x))
            x = F.relu(self.fc2(x))
            x = self.fc3(x)
            return x
    
    def validate_model(model, valid_dl, loss_func, log_images=False, batch_idx=0):
        "Compute performance of the model on the validation dataset and log a wandb.Table"
        model.eval()
        val_loss = 0.
        with torch.inference_mode():
            correct = 0
            for i, (images, labels) in enumerate(valid_dl):
                images, labels = images.to(device), labels.to(device)
    
                # Forward pass ‚û°
                outputs = model(images)
                val_loss += loss_func(outputs, labels)*labels.size(0)
    
                # Compute accuracy and accumulate
                _, predicted = torch.max(outputs.data, 1)
                correct += (predicted == labels).sum().item()
    
                # Log one batch of images to the dashboard, always same batch_idx.
                if i==batch_idx and log_images:
                    log_image_table(images, predicted, labels, outputs.softmax(dim=1))
        return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)
    
    def log_image_table(images, predicted, labels, probs):
        "Log a wandb.Table with (img, pred, target, scores)"
        # üêù Create a wandb Table to log images, labels and predictions to
        table = wandb.Table(columns=["image", "pred", "target"]+[f"score_{i}" for i in range(10)])
        for img, pred, targ, prob in zip(images.to("cpu"), predicted.to("cpu"), labels.to("cpu"), probs.to("cpu")):
            table.add_data(wandb.Image(img[0].numpy()*255), pred, targ, *prob.numpy())
        wandb.log({"predictions_table":table}, commit=False)

    import math
    # Initialize Wandb project
    wandb.init(
            project="cifar10-cnn-wandb",
            config={
                "epochs": 5,
                "batch_size": 128,
                "lr": 2e-3,
                "dropout": random.uniform(0.01, 0.80),
                "threshold_accuracy": 0.8
                },
            save_code=True)
    
    config = wandb.config
    
    # Load and transform CIFAR-10 data
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size, shuffle=True)
    testloader = torch.utils.data.DataLoader(testset, batch_size=config.batch_size, shuffle=False)
    
    n_steps_per_epoch = math.ceil(len(trainloader.dataset) / config.batch_size)
```
Finishing last run (ID:xivbf7yh) before initializing another...

View run **eternal-pine-3** at: [https://wandb.ai/ayamerushia/cifar10-cnn-wandb/runs/xivbf7yh](https://wandb.ai/ayamerushia/cifar10-cnn-wandb/runs/xivbf7yh)  
Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)

Find logs at: `./wandb/run-20240307_093720-xivbf7yh/logs`

Successfully finished last run (ID:xivbf7yh). Initializing new run:  

Tracking run with wandb version 0.16.4

Run data is saved locally in `/Users/fa-15566/ruangguru/github_rg/research-pribadi/bootcamp-ai/wandb/wandb/run-20240307_093756-f1m7acxw`

Syncing run **[polished-armadillo-4](https://wandb.ai/ayamerushia/cifar10-cnn-wandb/runs/f1m7acxw)** to [Weights & Biases](https://wandb.ai/ayamerushia/cifar10-cnn-wandb) ([docs](https://wandb.me/run))  

View project at [https://wandb.ai/ayamerushia/cifar10-cnn-wandb](https://wandb.ai/ayamerushia/cifar10-cnn-wandb)

View run at [https://wandb.ai/ayamerushia/cifar10-cnn-wandb/runs/f1m7acxw](https://wandb.ai/ayamerushia/cifar10-cnn-wandb/runs/f1m7acxw)


    Files already downloaded and verified
    Files already downloaded and verified

```python
    # Define model, optimizer, and loss function
    model = CNN().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)

    
    # Training loop
    for epoch in range(config.epochs):
        running_loss = 0.0
        example_ct = 0
        step_ct = 0
        for step, (images, labels) in enumerate(trainloader, 0):
            inputs, labels = images.to(device), labels.to(device)
    
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
    
            running_loss += loss.item()
    
            example_ct += len(inputs)
            metrics = {"train/train_loss": loss,
                        "train/epoch": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch,
                        "train/example_ct": example_ct}
            if step + 1 < n_steps_per_epoch:
                # üêù Log train metrics to wandb
                wandb.log(metrics)
            step_ct += 1
    
        val_loss, accuracy = validate_model(model, testloader, criterion, log_images=(epoch==(config.epochs-1)))
        val_metrics = {
            "val/val_loss": val_loss,
            "val/val_accuracy": accuracy
            }
        wandb.log({**metrics, **val_metrics})
        print(f"Train Loss: {loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}")
    
        if accuracy > config.threshold_accuracy:
            wandb.alert(
                title='Low Accuracy',
                text=f'Accuracy {accuracy} at step {step_ct} is below the acceptable theshold, {config.threshold_accuracy}',
            )
```

    Train Loss: 1.429, Valid Loss: 1.424600, Accuracy: 0.48
    Train Loss: 1.476, Valid Loss: 1.267869, Accuracy: 0.54
    Train Loss: 1.086, Valid Loss: 1.173016, Accuracy: 0.59
    Train Loss: 1.096, Valid Loss: 1.134961, Accuracy: 0.60
    Train Loss: 1.137, Valid Loss: 1.126435, Accuracy: 0.60

    wandb.finish()

table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%} .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% } .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }

### Run history:

  

train/epoch

‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà

train/example\_ct

‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà

train/train\_loss

‚ñà‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ

val/val\_accuracy

‚ñÅ‚ñÖ‚ñá‚ñà‚ñà

val/val\_loss

‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ

  

### Run summary:

  

train/epoch

5.0

train/example\_ct

50000

train/train\_loss

1.13669

val/val\_accuracy

0.6026

val/val\_loss

1.12644

  

View run **polished-armadillo-4** at: [https://wandb.ai/ayamerushia/cifar10-cnn-wandb/runs/f1m7acxw](https://wandb.ai/ayamerushia/cifar10-cnn-wandb/runs/f1m7acxw)  
Synced 6 W&B file(s), 1 media file(s), 129 artifact file(s) and 0 other file(s)

Find logs at: `./wandb/run-20240307_093756-f1m7acxw/logs`

Back to top


¬© Ruangguru Engineering 2024. All rights reserved