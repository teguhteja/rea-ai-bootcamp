   Stable Difussion Fine-tuning with Dreambooth ‚Äì Mastering AI Bootcamp 

[Mastering AI Bootcamp](../../../index.html)

Stable Difussion Fine-tuning with Dreambooth
============================================

*   Toolkit
    
    *   Python
        
        *   Jupyter Notebook
            
            *   [Jupyter Notebooks](../../../01_toolkits/00_python/00_jupyter-notebooks/00_installation-and-setup.html)
                
            *   [Notebook cells](../../../01_toolkits/00_python/00_jupyter-notebooks/01_notebook-cells.html)
                
            *   [Markdown and Formatting](../../../01_toolkits/00_python/00_jupyter-notebooks/02_markdown-and-formatting.html)
                
            *   [Kernel Management](../../../01_toolkits/00_python/00_jupyter-notebooks/03_kernel-management.html)
                
            *   [Magic Commands](../../../01_toolkits/00_python/00_jupyter-notebooks/04_magic-commands.html)
                
            *   [JupyterLab](../../../01_toolkits/00_python/00_jupyter-notebooks/05_jupyterlab.html)
                
        *   [Python Basics](../../../01_toolkits/00_python/01_python-basics.html)
            
        *   [Control Structures](../../../01_toolkits/00_python/02_control-structures.html)
            
        *   [Function](../../../01_toolkits/00_python/03_function.html)
            
        *   [Data Structures](../../../01_toolkits/00_python/04_data-structures.html)
            
        *   [Modules and Packages](../../../01_toolkits/00_python/05_modules-and-packages.html)
            
        *   [Working with Files](../../../01_toolkits/00_python/06_working-with-files.html)
            
        *   [Virtual Environments](../../../01_toolkits/00_python/07_virtual-environments.html)
            
        *   OOP
            
            *   [Object oriented programming: Fitting functionality into single objects](../../../01_toolkits/00_python/08_oop/00_oop.html)
                
            *   [Inheritance](../../../01_toolkits/00_python/08_oop/01_oop_inheritance.html)
                
    *   Version Control
        
        *   [Introduction to Version Control](../../../01_toolkits/01_version-control/00_introduction-to-version-control.html)
            
        *   [Git Introduction](../../../01_toolkits/01_version-control/01_introduction-git.html)
            
        *   Git Command
            
            *   [`Init`](../../../01_toolkits/01_version-control/02_git-command-local/00_init.html)
                
            *   [Snapshotting](../../../01_toolkits/01_version-control/02_git-command-local/01_snapshotting.html)
                
            *   [`git remote add`](../../../01_toolkits/01_version-control/02_git-command-local/02_git-remote.html)
                
            *   [Basic branch and merge](../../../01_toolkits/01_version-control/02_git-command-local/03_basic-branch-and-merge.html)
                
            *   [`.gitignore`](../../../01_toolkits/01_version-control/02_git-command-local/04_gitignore.html)
                
        *   [Github](../../../01_toolkits/01_version-control/03_github.html)
            
    *   Fundamental of Statistics
        
        *   [Descriptive Statistics](../../../01_toolkits/02_foundational_statistics/00_descriptive_statistics.html)
            
        *   [Fundamentals of Probability](../../../01_toolkits/02_foundational_statistics/01_fundamentals_of_probability.html)
            
        *   [Data Analysis and Interpretation](../../../01_toolkits/02_foundational_statistics/02_data_analysis_and_interpretation.html)
            
        *   [Distributions in Statistics](../../../01_toolkits/02_foundational_statistics/03_distributions_statistics.html)
            
        *   [Bayesian Theory](../../../01_toolkits/02_foundational_statistics/04_bayesian_theory.html)
            
    *   [Pandas](../../../01_toolkits/03_pandas/00_pandas.html)
        
    *   [Visualization](../../../01_toolkits/04_visualization/00_visualization.html)
        
*   * * *
    
*   Machine Learning Fundamental
    
    *   [What is Machine Learning](../../../02_machine-learning-fundamental/00_what-is-machine-learning.html)
        
    *   [Introduction to Machine Learning](../../../02_machine-learning-fundamental/01_machine-learning-fundamental.html)
        
    *   [Linear Regression](../../../02_machine-learning-fundamental/02_linear-equation.html)
        
    *   [Supervised Learning](../../../02_machine-learning-fundamental/03_supervised-learning.html)
        
    *   [Scalar](../../../02_machine-learning-fundamental/04_matrix-and-vector.html)
        
    *   [Visualizing linear algebra as vector spaces](../../../02_machine-learning-fundamental/05_linear-algebra.html)
        
    *   [k-Nearest Neighbors (kNN)](../../../02_machine-learning-fundamental/06_knn.html)
        
    *   [Classification](../../../02_machine-learning-fundamental/07_classification.html)
        
    *   [Decision Tree](../../../02_machine-learning-fundamental/08_decision-tree.html)
        
    *   [Support Vector Machines](../../../02_machine-learning-fundamental/09_svm.html)
        
    *   [Direction of a vector](../../../02_machine-learning-fundamental/10_supplemental_svm.html)
        
    *   [Unsupervised Learning](../../../02_machine-learning-fundamental/11_unsupervised-learning.html)
        
    *   [Anomaly Detection](../../../02_machine-learning-fundamental/12_anomaly-detection.html)
        
    *   [Principal Component Analysis](../../../02_machine-learning-fundamental/13_pca.html)
        
    *   [Covariance formula and variance](../../../02_machine-learning-fundamental/14_supplemental-pca.html)
        
*   * * *
    
*   Deep Learning
    
    *   [Deep Learning](../../../03_deep-learning/00_deep-learning.html)
        
    *   [Deep Learning Model](../../../03_deep-learning/01_deep-learning-model.html)
        
    *   [Calculus](../../../03_deep-learning/02_calculus-for-deep-learning.html)
        
    *   [Gradient Descend and Backpropagation](../../../03_deep-learning/03_gradient-descent-and-backpropagation.html)
        
    *   [Pytorch Basic](../../../03_deep-learning/04_pytorch-basic.html)
        
    *   [Gradient Descent with PyTorch](../../../03_deep-learning/05_pytorch-gradient-descent.html)
        
    *   [Pytorch Dimension Modification](../../../03_deep-learning/06_pytorch-dimension.html)
        
    *   [Pytorch Application](../../../03_deep-learning/07_pytorch-application.html)
        
    *   [Pytorch MNIST](../../../03_deep-learning/08_pytorch-mnist.html)
        
*   * * *
    
*   Model Usage
    
    *   Introduction
        
        *   [Hugging Face](../../../04_model-usage/00-introduction/00_transformers_hugging_face.html)
            
    *   Pipeline
        
        *   [Pipelines](../../../04_model-usage/01-pipeline/00_pipeline.html)
            
        *   [Choosing the Right Processing Unit for Machine Learning: CPU, GPU, or TPU?](../../../04_model-usage/01-pipeline/01_cpu-gpu-tpu.html)
            
    *   Model Hub
        
        *   [Model Hub üóÉÔ∏è](../../../04_model-usage/02-model-hub/00_models.html)
            
    *   Transfer Learning
        
        *   [Transfer Learning](../../../04_model-usage/03-transfer-learning/00_transfer_learning.html)
            
        *   [Model Deployment](../../../04_model-usage/03-transfer-learning/01_model_deployment.html)
            
    *   Gradio
        
        *   [Gradio](../../../04_model-usage/04-gradio/00_gradio.html)
            
*   * * *
    
*   Database
    
    *   SQL
        
        *   [SQL Fundamentals with Python - Database](../../../05_database/00_sql/00_sql-database.html)
            
        *   [SQL Fundamentals with Python - Tables](../../../05_database/00_sql/01_sql-table.html)
            
        *   [SQL Fundamentals with Python - Joins](../../../05_database/00_sql/02_sql-joins.html)
            
    *   Elasticsearch
        
        *   [Introduction to Elasticsearch](../../../05_database/01_elasticsearch/00_introduction.html)
            
        *   [Installation and Configuration](../../../05_database/01_elasticsearch/01_installation-and-configuration.html)
            
        *   [Data Modeling](../../../05_database/01_elasticsearch/02_data-modeling.html)
            
        *   [Elasticsearch In Practice](../../../05_database/01_elasticsearch/03_elasticsearch-in-practice.html)
            
        *   [Query](../../../05_database/01_elasticsearch/04_query.html)
            
        *   [Snapshot](../../../05_database/01_elasticsearch/05_snapshot.html)
            
*   * * *
    
*   Computer Vision
    
    *   CNN
        
        *   [Computer Vision](../../../06_computer-vision/00_cnn/00_cnn-intro.html)
            
        *   [Hello World in Image Classification](../../../06_computer-vision/00_cnn/01_nn-vs-cnn.html)
            
        *   [CIFAR10 comparison for regular Neural Network vs CNN](../../../06_computer-vision/00_cnn/02_nn-vs-cnn-cifar10.html)
            
        *   [Convolution Layer](../../../06_computer-vision/00_cnn/03_convolution-layer.html)
            
        *   [POOLING LAYER](../../../06_computer-vision/00_cnn/04_pooling-layer.html)
            
        *   [Fully Connected Layer](../../../06_computer-vision/00_cnn/05_fully-connected-layer.html)
            
        *   [Training](../../../06_computer-vision/00_cnn/06_training.html)
            
        *   [Pretrained CNN Model](../../../06_computer-vision/00_cnn/07_pretrained-model.html)
            
        *   [Applied CNN: Object Detection and YOLO in Action](../../../06_computer-vision/00_cnn/08_object-detection.html)
            
    *   Stable Diffusion
        
        *   Introduction
            
            *   [Intro to Stable Diffusion](../../../06_computer-vision/01_stable-diffusion/00_intro/intro.html)
                
        *   Basic
            
            *   [Stable Diffusion - Basic](../../../06_computer-vision/01_stable-diffusion/01_basic/Stable_Diffusion_Basic.html)
                
        *   Fine Tuning
            
            *   [Stable Difussion Fine-tuning with Dreambooth](../../../06_computer-vision/01_stable-diffusion/02_fine_tuning/Stable_Diffusion_Fine_tuning.html)
                
        *   ControlNet
            
            *   [ControlNet with Stable Diffusion](../../../06_computer-vision/01_stable-diffusion/03_controlnet/Stable_Diffusion_ControlNet.html)
                
*   * * *
    
*   NLP
    
    *   [Intuition](../../../07_nlp/00_intuition.html)
        
    *   [Preprocessing](../../../07_nlp/01_preprocess.html)
        
    *   [Feature extraction](../../../07_nlp/02_feature_extraction.html)
        
    *   [Second architecture: Using Word Embedding for sentiment classification](../../../07_nlp/03_word_embedding_intuition.html)
        
    *   [ASCII](../../../07_nlp/04_word_embedding.html)
        
    *   [Generate Word Embedding With Word2Vec](../../../07_nlp/05_word2vec.html)
        
    *   [RNN](../../../07_nlp/06_RNN.html)
        
    *   [Seq2Seq With RNN](../../../07_nlp/07_Seq2Seq_with_RNN.html)
        
    *   [Problem With RNN](../../../07_nlp/08_attention.html)
        
    *   [Understanding Different Transformer Architectures](../../../07_nlp/09_understanding_different_architectures.html)
        
*   * * *
    
*   Langchain
    
    *   Prompt Engineering
        
        *   [NovelAI](../../../08_langchain/00_prompt-engineering/00_NovelAI.html)
            
        *   [Intro to Prompt in Generative AI](../../../08_langchain/00_prompt-engineering/01_intro-to-prompt-engineering.html)
            
    *   [API with FastAPI](../../../08_langchain/01_fast_api.html)
        
    *   [LangChain: A Python Library for Building NLP Applications](../../../08_langchain/02_intro_to_langchain.html)
        
    *   [Basic Usage LangChain](../../../08_langchain/03-basic_langchain.html)
        
    *   Chain
        
        *   [Chain](../../../08_langchain/04_chain/00_chain.html)
            
        *   [Chain Exercise](../../../08_langchain/04_chain/01_chain_exercise.html)
            
        *   [Chain Exercise](../../../08_langchain/04_chain/02_chain_exercise_answer.html)
            
    *   [Agent](../../../08_langchain/05_agent.html)
        
    *   [Memory and LangChain](../../../08_langchain/06_memory.html)
        
    *   [Memory Exercise Answer Key](../../../08_langchain/06-memory-exercise-answer-key.html)
        
    *   [Communicating with Embedded Data in Documents](../../../08_langchain/07.qna-with-data-in-the-document.html)
        
*   * * *
    
*   Machine Learning Operations
    
    *   Docker
        
        *   [Introduction to Docker](../../../09_mlops/00_docker/00_intro_setup_docker.html)
            
        *   [Building Docker Images for Python Apps](../../../09_mlops/00_docker/01_build_docker_images.html)
            
        *   [Deploying Python Apps with Docker Compose](../../../09_mlops/00_docker/02_deploy_docker_images.html)
            
    *   Wan DB
        
        *   [Introduction to WanDB](../../../09_mlops/01_wandb/00_wandb_intro_setup.html)
            
        *   [Dashboards in WanDB](../../../09_mlops/01_wandb/01_wandb_dashboard.html)
            
        *   [Cnn and Wandb Tracking](../../../09_mlops/01_wandb/cnn_and_wandb_tracking.html)
            
        *   [Fine-tuning a model on a text classification task](../../../09_mlops/01_wandb/Text_Classification_on_GLUE.html)
            

On this page
------------

- [Stable Difussion Fine-tuning with Dreambooth](#stable-difussion-fine-tuning-with-dreambooth)
  - [On this page](#on-this-page)
- [Stable Difussion Fine-tuning with Dreambooth](#stable-difussion-fine-tuning-with-dreambooth-1)
  - [Methods of Fine Tuning](#methods-of-fine-tuning)
  - [Implementation](#implementation)
    - [Installing the libraries](#installing-the-libraries)
    - [Loading the model](#loading-the-model)
    - [Training](#training)
      - [Creating the Instance and Class Prompts](#creating-the-instance-and-class-prompts)
      - [Creating Directories and JSON File](#creating-directories-and-json-file)
      - [Upload Training Images](#upload-training-images)
      - [Specifying Parameters](#specifying-parameters)
      - [Execute Training](#execute-training)
    - [Images and model weights are stored](#images-and-model-weights-are-stored)
  - [Convert the weights into (checkpoint)](#convert-the-weights-into-checkpoint)
  - [Inference / Generating images (tests the fine tune model)](#inference--generating-images-tests-the-fine-tune-model)
    - [Testing multiple prompts](#testing-multiple-prompts)
    - [More prompt examples](#more-prompt-examples)
  - [Saving the results](#saving-the-results)
  - [Exercise Fine Tuning](#exercise-fine-tuning)

Stable Difussion Fine-tuning with Dreambooth
============================================

Imagine the scenario where we need to generate images that resemble a specific person‚Äôs face, but that face is not included in the model‚Äôs training data, we would rely on the model‚Äôs ability to generalize from its learned representations. fine-tuning is a great approach for this scenario.

The model, after being trained on a diverse set of faces, should have grasped the underlying patterns and features common to human faces. A representation of a specific person‚Äôs face, such as a sketch or a description, would be inputted, and the model would generate a new face that aligns with the input as closely as possible.

Fine-tuning is a technique used to train a custom model based on existing models, enabling the generation of custom images.

For example, personal photos can be added to the model, allowing it to generate unique images in various scenarios such as mountains, forests, streets, and so on.

Methods of Fine Tuning
----------------------

There are several methods to apply fine tuning:

1.  **Additional Training**

This involves training a base model with an additional dataset. For instance, you can train stable diffusion with an additional old car dataset to orient the aesthetics of the cars to that specific type.

2.  **Dreambooth Algorithm**

Initially developed by Google, this technique allows for injecting custom subjects into the models. Due to its architecture, it is possible to achieve great results using only 3 or 5 custom images.

//<!\[CDATA\[ window.\_\_mirage2 = {petok:"jgm3M6Tijz9n9uoHvxu8DiorQmDhWwo5QMAbRdxepIg-1800-0.0.1.1"}; //\]\]> 

![](https://storage.googleapis.com/rg-ai-bootcamp/stable-diffusion/dreambooth-high-level.png)

Dreambooth

[Source](https://dreambooth.github.io/)

In this course, the focus is on using the Dreambooth algorithm for fine-tuning the Stable Diffusion model.

Implementation
--------------

In the implementation, we‚Äôll use an image of a name in his 30s that we‚Äôll call John. This man was generated using Stable Diffusion to avoid copyright infringement. You can simply use a picture of yourself if you want to try things out.

![](https://storage.googleapis.com/rg-ai-bootcamp/stable-diffusion/john.png)

John

### Installing the libraries

    !wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py
    !wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py
    %pip install -qq git+https://github.com/ShivamShrirao/diffusers
    %pip install -q -U --pre triton
    %pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers

### Loading the model

    model_sd = "runwayml/stable-diffusion-v1-5"
    output_dir = "/content/stable_diffusion_weights/john"

    !mkdir -p $output_dir

### Training

Dreambooth training requires a unique identifier, the class name, and images of the subject to be inserted. The images form the dataset. The unique identifier needs to be a term associated with no concept or feature recognized by the model. The class is the type of object you want to generate.

Three components are needed:

1.  **Unique Identifier**

This is a unique name that does not exist in the model. In our case, we will use john.

2.  **Class Name**

This is the type of object that will be generated. In our case, we will generate faces of people.

3.  **images**

These are the training datasets. In our case, we have uploaded ten images.

Instance prompt a photo of \[unique identifier\] \[class name\]

Class prompt > a photo of \[class name\]

The instance prompt will be as follows: > a photo of john person

As the subject is a person, the class prompt will be as follows: > a photo of a person

In this demonstration, we‚Äôll be utilizing photos of John as basis to train the Stable Diffusion Model, aiming to generate images similar to John.

#### Creating the Instance and Class Prompts

We need to create a new variable concepts\_list. It will be a list in Python. Then we need to specify the parameters.

    concepts_list = [
        {
            "instance_prompt": "john",
            "class_prompt": "photo of a person",
            "instance_data_dir": "/content/data/john",
            "class_data_dir": "/content/data/person"
        }
    ]

#### Creating Directories and JSON File

We need to create directories and convert this variable into a JSON file

    import json
    import os
    import random
    
    for c in concepts_list:
      os.makedirs(c["instance_data_dir"], exist_ok=True)

    with open("concepts_list.json", "w") as f:
      json.dump(concepts_list, f, indent=4)

#### Upload Training Images

1.  Ensure that images are of size 512 x 512. If they are not, need to resize them.
2.  Use the file upload feature in the left sidebar.
3.  Move the images to folder `/content/data/john`

#### Specifying Parameters

We need to specify some parameters before running the algorithm

    num_imgs = 15
    num_class_images = num_imgs * 12
    max_num_steps = num_imgs * 100
    learning_rate = 1e-6
    lr_warmup_steps = int(max_num_steps / num_imgs)

    print(num_imgs, num_class_images, max_num_steps, learning_rate, lr_warmup_steps)

    15 180 1500 1e-06 100

The `learning_rate` is a hyperparameter that determines the step size at which an optimization algorithm (like gradient descent) proceeds while learning from the data. It controls how much to change the model in response to the estimated error each time the model weights are updated.

If the learning rate is too small, the model will need many updates to converge to the best values, which can take a long time. On the other hand, if the learning rate is too large, the updates may be too significant and the model may pass over the optimal solution, or even diverge.

* * *

`lr_warmup_steps` is a hyperparameter used in the learning rate scheduling strategy, specifically in the warmup phase of training.

Learning rate warmup is a strategy where the learning rate is initially set to a small value and gradually increased to the maximum or initial learning rate. This is done over a certain number of steps or epochs, which is what `lr_warmup_steps` refers to.

The purpose of this strategy is to prevent the model from overfitting early in the training process. By starting with a smaller learning rate, the model makes smaller adjustments and doesn‚Äôt converge too quickly to a suboptimal solution. After the warmup steps, the learning rate is increased to allow the model to learn more quickly and converge to the optimal solution.

#### Execute Training

Finally, we can train the algorithm

    !python3 train_dreambooth.py \
      --pretrained_model_name_or_path=$model_sd \
      --pretrained_vae_name_or_path="stabilityai/sd-vae-ft-mse" \
      --instance_data_dir=$output_dir \
      --output_dir=$output_dir \
      --revision="fp16" \
      --with_prior_preservation --prior_loss_weight=1.0 \
      --seed=777 \
      --resolution=512 \
      --train_batch_size=1 \
      --train_text_encoder \
      --mixed_precision="fp16" \
      --use_8bit_adam \
      --gradient_accumulation_steps=1 \
      --learning_rate=$learning_rate \
      --lr_scheduler="constant" \
      --lr_warmup_steps=$lr_warmup_steps \
      --num_class_images=$num_class_images \
      --sample_batch_size=4 \
      --max_train_steps=$max_num_steps \
      --save_interval=10000 \
      --save_sample_prompt="john" \
      --concepts_list="concepts_list.json"

This process will take about 20 minutes to finish. If an error occurs during training, ensure that the images or datasets are in the correct folder. Once the training is complete, we can proceed to perform the first tests.

### Images and model weights are stored

The weights directory is a specific location in the file system where the weights of a trained machine learning model are stored.

These weights are the learned parameters that the model uses to make predictions or decisions.

They are typically saved so that the model can be reused later, either for further training, for fine-tuning on a different task, or for direct inference.

    from natsort import natsorted
    from glob import glob
    import os
    
    weights_dir = natsorted(glob(output_dir + os.sep + '*'))[-1]
    print('Weights directory: ', weights_dir)

    Weights directory:  /content/stable_diffusion_weights/john/1500

    import os
    import matplotlib.pyplot as plt
    from PIL import Image
    
    # function to display images in grid
    def grid_img(imgs, rows=1, cols=3, scale=1):
      assert len(imgs) == rows * cols
    
      w, h = imgs[0].size
      w, h = int(w*scale), int(h*scale)
    
      grid = Image.new('RGB', size=(cols*w, rows*h))
      grid_w, grid_h = grid.size
    
      for i, img in enumerate(imgs):
          img = img.resize((w,h), Image.ANTIALIAS)
          grid.paste(img, box=(i%cols*w, i//cols*h))
      return grid

    weights_folder = output_dir
    folders = sorted([f for f in os.listdir(weights_folder) if f != "0"], key = lambda x: int(x))
    
    imgs_test = []
    
    for imgs, folder in enumerate(folders):
      folder_path = os.path.join(weights_folder, folder)
      image_folder = os.path.join(folder_path, "samples")
      images = [f for f in os.listdir(image_folder)]
    
      for i in images:
        img_path = os.path.join(image_folder, i)
        r = Image.open(img_path)
        imgs_test.append(r)
    
    # show images that generated after training
    grid_img(imgs_test, rows=1, cols=4, scale=1)

    DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.
      img = img.resize((w,h), Image.ANTIALIAS)

![](Stable_Diffusion_Fine_tuning_files/figure-html/cell-13-output-2.png)

Convert the weights into (checkpoint)
-------------------------------------

Checkpoints are used to save and load the progress of training, allowing you to resume training from the exact point it was stopped.

Converting the weights into a checkpoint involves saving the current state of the model, including its learned weights, into a format that can be easily loaded later.

This process allows for the model‚Äôs state to be preserved, so that the training process can be resumed later if needed, or the trained model can be used for generating images.

    ckpt_path = weights_dir + "/model.ckpt"
    
    half_arg = "--half"
    
    !python convert_diffusers_to_original_stable_diffusion.py --model_path $weights_dir  --checkpoint_path $ckpt_path $half_arg
    print(f"Converted to ckpt and saved in {ckpt_path}")

Inference / Generating images (tests the fine tune model)
---------------------------------------------------------

    import torch
    from torch import autocast
    from diffusers import StableDiffusionPipeline, DDIMScheduler
    from IPython.display import display

    model_path = weights_dir
    print(model_path)

    /content/stable_diffusion_weights/john/1500

    pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16).to('cuda')

    pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)
    pipe.enable_xformers_memory_efficient_attention()
    
    pipe.safety_checker = lambda images, clip_input: (images, False)
    
    seed = 555

    prompt = "face portrait of john playing guitar in the restaurant, realistic, hd, vivid, sunset"
    negative_prompt = "bad anatomy, ugly, deformed, desfigured, distorted face, poorly drawn hands, poorly drawn face, poorly drawn feet, blurry, low quality, low definition, lowres, out of frame, out of image, cropped, cut off, signature, watermark"
    num_samples = 5
    guidance_scale = 7.5
    num_inference_steps = 30
    height = 512
    width = 512
    
    seed = 123
    print("Seed: {}".format(str(seed)))
    generator = torch.Generator(device='cuda').manual_seed(seed)
    
    with autocast("cuda"), torch.inference_mode():
        imgs = pipe(
            prompt,
            negative_prompt=negative_prompt,
            height=height, width=width,
            num_images_per_prompt=num_samples,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            generator=generator
        ).images
    
    for img in imgs:
        display(img)

    Seed: 123

{"model\_id":"857000fe663849508e49afef2706503c","version\_major":2,"version\_minor":0,"quarto\_mimetype":"application/vnd.jupyter.widget-view+json"}

![](Stable_Diffusion_Fine_tuning_files/figure-html/cell-19-output-3.png)

![](Stable_Diffusion_Fine_tuning_files/figure-html/cell-19-output-4.png)

![](Stable_Diffusion_Fine_tuning_files/figure-html/cell-19-output-5.png)

![](Stable_Diffusion_Fine_tuning_files/figure-html/cell-19-output-6.png)

![](Stable_Diffusion_Fine_tuning_files/figure-html/cell-19-output-7.png)

### Testing multiple prompts

    prompt = ["photo of john person, closeup, mountain fuji in the background, natural lighting",
              "photo of john person in the desert, closeup, pyramids in the background, natural lighting, frontal face",
              "photo of john person in the forest, natural lighting, frontal face",
              "photo of john person as an astronaut, natural lighting, frontal face, closeup, starry sky in the background",
              "face portrait of john in the snow, realistic, hd, vivid, sunset"]
    
    negative_prompt = ["bad anatomy, ugly, deformed, desfigured, distorted face, poorly drawn hands, poorly drawn face, poorly drawn feet, blurry, low quality, low definition, lowres, out of frame, out of image, cropped, cut off, signature, watermark" ] * len(prompt)
    num_samples = 1
    guidance_scale = 8
    num_inference_steps = 75
    height = 512
    width = 512
    
    seed = 88
    print("Seed: {}".format(str(seed)))
    generator = torch.Generator(device='cuda').manual_seed(seed)
    
    with autocast("cuda"), torch.inference_mode():
        imgs = pipe(
            prompt,
            negative_prompt=negative_prompt,
            height=height, width=width,
            num_images_per_prompt=num_samples,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            generator=generator
        ).images
    
    for img in imgs:
        display(img)

    Seed: 88

{"model\_id":"09f4e9cb09ae43e594b0539edfd8dd07","version\_major":2,"version\_minor":0,"quarto\_mimetype":"application/vnd.jupyter.widget-view+json"}

![](Stable_Diffusion_Fine_tuning_files/figure-html/cell-20-output-3.png)

![](Stable_Diffusion_Fine_tuning_files/figure-html/cell-20-output-4.png)

![](Stable_Diffusion_Fine_tuning_files/figure-html/cell-20-output-5.png)

![](Stable_Diffusion_Fine_tuning_files/figure-html/cell-20-output-6.png)

![](Stable_Diffusion_Fine_tuning_files/figure-html/cell-20-output-7.png)

### More prompt examples

*   in the forest, in cairo, in cairo desert, in a western scene, in star wars, in mountain fuji, in the snow, etc.

> Other combinations:

*   `photo of john person, closeup, mountain fuji in the background, natural lighting`
    
*   `digital painting of john in the snow, realistic, hd, vivid, sunset`
    
*   `watercolor painting of john person, realistic, blue and orange tones`
    
*   `digital painting of john person, hyperrealistic, fantasy, Surrealist, painted by Alphonse Mucha`
    
*   `painting of john person in star wars, realistic, 4k ultra hd, blue and red tones`
    
*   `photo of john person, in an armor, realistic, visible face, colored, detailed face, ultra detailed, natural lighting`
    
*   `photo of john person, cyberpunk, vivid, realistic, 4k ultra hd`
    
*   `anime painting of john person, chill day, by tim okamura, noah bradley, trending on artstation`
    

Saving the results
------------------

    !mkdir results

    mkdir: cannot create directory ‚Äòresults‚Äô: File exists

    for i, img in enumerate(imgs):
      img.save('results/result_{}.png'.format(i+1))

Exercise Fine Tuning
--------------------

    # Installing Libs
    !wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py
    !wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py
    %pip install -qq git+https://github.com/ShivamShrirao/diffusers
    %pip install -q -U --pre triton
    %pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers
    %pip install rggrader

    # @title #### Student Identity
    student_id = "your student id" # @param {type:"string"}
    name = "your name" # @param {type:"string"}

    # @title #### 00. Fine-tuning with Dreambooth
    from rggrader import submit_image
    import torch
    from torch import autocast
    from diffusers import StableDiffusionPipeline, DDIMScheduler
    from IPython.display import display
    import os
    import matplotlib.pyplot as plt
    from PIL import Image
    from natsort import natsorted
    from glob import glob
    import json
    import random
    
    # TODO:
    # 1. Load Model: Load 'runwayml/stable-diffusion-v1-5'.
    # 2. Prepare Images: use your photos to train the provided model.
    # 3. Fine-Tune: Train the model on your dataset.
    # 4. Generate Faces: Use the fine-tuned model to create new faces.
    # 5. Save Results: Store the generated images in the 'results' folder.
    # 6. Upload Image: Choose one image from 'results' and upload it for review.
    
    # Note: Create folder '/content/data/input_image' to upload Training Image
    
    # Loading model and create output dir
    model_sd = "runwayml/stable-diffusion-v1-5"
    output_dir = "/content/stable_diffusion_weights/student_data"
    !mkdir -p $output_dir
    
    # Put your code here:
    imgs = None
    
    # ---- End of your code ----
    
    # Saving the results
    !mkdir results
    for i, img in enumerate(imgs):
        img.save('results/result_{}.png'.format(i+1))

    # Submit Method
    assignment_id = "00_fine_tuning"
    question_id = "00_fine_tuning_with_dreambooth"
    submit_image(student_id, question_id, 'your_image.png') # change 'your_image.png' to the name of the image you want to upload (eg. results/result_3.png)

Back to top



¬© Ruangguru Engineering 2024. All rights reserved